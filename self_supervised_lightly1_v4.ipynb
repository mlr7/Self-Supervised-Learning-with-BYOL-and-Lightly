{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction: Self-Supervised Learning with BYOL (Bootstrap Your Own Latent)**\n"
      ],
      "metadata": {
        "id": "vTHn2tPC2Hdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-supervised learning** is a form of unsupervised learning where the system learns to predict part of its input from other parts of its input. The key idea is to create a supervised learning task from unlabeled data, allowing the model to learn representations that can be useful for a wide range of tasks without the need for manually annotated labels. This approach leverages the inherent structure in the data to generate labels from the data itself, often through cleverly designed **pretext tasks**. It has become increasingly popular due to its ability to leverage large amounts of unlabeled data, significantly reducing the dependence on expensive labeled datasets.    \n",
        "    \n",
        "## **General Process**\n",
        "**Pretext Task Creation**: A pretext task is created from the unlabeled data. The nature of this task can vary widely but is designed so that solving it will require the model to understand and learn meaningful representations of the data.   \n",
        "\n",
        "**Model Training**: The model is trained on this self-generated supervised task, learning to predict the artificially created labels from the input data.\n",
        "\n",
        "**Feature Extractio**: After training, the learned representations (features) can be used for **downstream tasks**. These tasks are often the actual target tasks we care about, such as classification, detection, or segmentation in vision, and various NLP tasks in text.\n",
        "\n",
        "## **Popular Approaches**\n",
        "\n",
        "**Contrastive Learning**: This approach involves learning representations by contrasting positive pairs against negative pairs. A positive pair consists of two different augmentations of the same data point, while negative pairs are generated from different data points. The model learns by bringing the representations of positive pairs closer and pushing those of negative pairs apart. Examples include SimCLR and MoCo.\n",
        "\n",
        "**Cluster-Based Learning**: Techniques like DeepCluster and SeLa work by clustering the feature space to assign pseudo-labels to the data, then training the model to predict these cluster assignments. This cyclic process of clustering and prediction helps in learning useful features.\n",
        "\n",
        "**Prediction-Based Methods**: These methods involve predicting some part of the data from another. Examples include predicting the future frames in a video or the missing part of an image. In natural language processing (NLP), a popular method is predicting the next word in a sentence, as seen in models like BERT, which predicts masked words in a sentence.\n",
        "\n",
        "**BYOL (Bootstrap Your Own Latent)**: A novel approach that avoids the need for negative pairs by training two networks simultaneously: an online network and a target network. The online network learns to predict the target network's representation of the same data point under a different augmentation.\n",
        "\n",
        "**SimSiam**: Similar to BYOL, SimSiam operates without negative pairs but simplifies the architecture by not using a moving average target network. Instead, it employs a stop-gradient operation to prevent collapsing.\n",
        "\n",
        "## **Advantages and Challenges**\n",
        "### **Advantages**:\n",
        "\n",
        "* Reduces the reliance on expensive labeled data.\n",
        "\n",
        "* Can leverage vast amounts of unlabeled data available.\n",
        "\n",
        "* Learned representations are often more generalizable across different tasks.\n",
        "\n",
        "### **Challenges**:\n",
        "\n",
        "* Designing effective pretext tasks is non-trivial and often domain-specific.\n",
        "\n",
        "* Some approaches, particularly contrastive learning, require careful negative pair sampling to avoid trivial solutions.\n",
        "\n",
        "\n",
        "It is on ongoing research question as to the best practices for transferring self-supervised learning features to downstream tasks.\n",
        "\n",
        "Self-supervised learning has the continuing potential to unlock more scalable and efficient ways to learn from data. Self-supervised learning development continues to be an area of active research, with new methods and improvements being proposed regularly.\n",
        "\n",
        "In this notebook we are going to implement the BYOL approach to self-supervised learning learning the Lightly Python library (https://pypi.org/project/lightly/)."
      ],
      "metadata": {
        "id": "qOxKXvOv21ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Installs**"
      ],
      "metadata": {
        "id": "dW28OglUvX4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GTb7FXaKatF8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "042c3712-2a0c-45fe-ffc7-bca27661a342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly\n",
            "  Downloading lightly-1.5.0-py3-none-any.whl (733 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.1/733.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2024.2.2)\n",
            "Collecting hydra-core>=1.0.0 (from lightly)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightly-utils~=0.0.0 (from lightly)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.31.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.0.7)\n",
            "Collecting pydantic<2,>=1.10.5 (from lightly)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from lightly)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lightly) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly) (0.16.0+cu121)\n",
            "Collecting pytorch-lightning>=1.0.4 (from lightly)\n",
            "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly-utils~=0.0.0->lightly) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.10.5->lightly) (4.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.0.4->lightly)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.8.0 (from pytorch-lightning>=1.0.4->lightly)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (2.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.0.4->lightly) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lightly) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (4.0.3)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=bc59c8112bd43760ea19df151dbc9b394f4e05df56543a6733b52561f38a4d48\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, pydantic, omegaconf, lightning-utilities, lightly-utils, hydra-core, torchmetrics, pytorch-lightning, lightly\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.3\n",
            "    Uninstalling pydantic-2.6.3:\n",
            "      Successfully uninstalled pydantic-2.6.3\n",
            "Successfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 lightly-1.5.0 lightly-utils-0.0.2 lightning-utilities-0.10.1 omegaconf-2.3.0 pydantic-1.10.14 pytorch-lightning-2.2.0.post0 torchmetrics-1.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydantic",
                  "pydevd_plugins"
                ]
              },
              "id": "8687a73b86284f6ba71673cee5c78aa0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install lightly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Imports**"
      ],
      "metadata": {
        "id": "SHl5EhP1vaf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y297f9a4aihK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
        "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
        "from lightly.transforms.byol_transform import (\n",
        "    BYOLTransform,\n",
        "    BYOLView1Transform,\n",
        "    BYOLView2Transform,\n",
        ")\n",
        "from lightly.utils.scheduler import cosine_schedule"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Definition**\n",
        "\n",
        "**BYOL (Bootstrap Your Own Latent)** is a novel approach to **self-supervised learning** introduced in a paper by Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos, and Michal Valko. The main idea behind BYOL is to train a deep neural network to learn powerful representations without relying on negative samples, which is a common requirement in many other self-supervised learning frameworks.\n",
        "\n",
        "### **Mechanics of BYOL**:\n",
        "\n",
        "**Architecture**: BYOL utilizes a dual-network architecture consisting of a target network and an online network. Both networks have the same architecture but do not share weights. The online network is updated through backpropagation during training, while the target network's weights are updated as a slow-moving average of the online network's weights. This means the target network evolves more smoothly over time.\n",
        "\n",
        "**Learning Process**: The core idea is to make the representation of an augmented version of an image (produced by the online network) similar to the representation of another augmented version of the same image (produced by the target network). BYOL uses two sets of data augmentations to create these two different views of the same image. These augmentations can include cropping, resizing, color jittering, etc.\n",
        "\n",
        "**Loss Function**: The similarity between the representations is measured using a loss function (e.g., mean squared error). The goal is to minimize the distance between the representations of the two augmented views of the same image as produced by the online and target networks, respectively.\n",
        "\n",
        "**No Negative Pairs**: Unlike contrastive learning approaches that require comparing positive pairs (similar or the same data points) with negative pairs (dissimilar data points) to learn useful features, BYOL does not use negative pairs. It only relies on positive pairs and still learns useful representations. This is significant because managing negative pairs can be challenging and computationally expensive in large datasets.\n",
        "\n",
        "**Update Mechanism**: The target network's parameters are updated as an exponential moving average of the online network's parameters. This update mechanism is key to BYOL's performance, as it provides stability to the learning process and helps in learning consistent representations.\n",
        "\n",
        "Grill, Jean-Bastien, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch et al. \"Bootstrap your own latent-a new approach to self-supervised learning.\" Advances in neural information processing systems 33 (2020): 21271-21284."
      ],
      "metadata": {
        "id": "N_IN05pgvd3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9EulbM19aohw"
      },
      "outputs": [],
      "source": [
        "class BYOL(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n",
        "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        deactivate_requires_grad(self.backbone_momentum)\n",
        "        deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NmUEBe5wbaJo"
      },
      "outputs": [],
      "source": [
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = BYOL(backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flG_wIFXbdkh",
        "outputId": "a760c2bf-26ee-4312-efbe-f55f9f514a6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BYOL(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (projection_head): BYOLProjectionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (prediction_head): BYOLPredictionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=1024, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (backbone_momentum): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (projection_head_momentum): BYOLProjectionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transforms and Data Loading**\n"
      ],
      "metadata": {
        "id": "2KSSdp30wnyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qMnVKbAFbgGp"
      },
      "outputs": [],
      "source": [
        "# Disable resizing and gaussian blur for cifar10.\n",
        "transform = BYOLTransform(\n",
        "    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n",
        "    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7uqeRsiblQV",
        "outputId": "ca7e73f9-1ebf-40d2-e3cd-abf49128eaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:09<00:00, 18455263.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/cifar10/cifar-10-python.tar.gz to datasets/cifar10\n"
          ]
        }
      ],
      "source": [
        "dataset = torchvision.datasets.CIFAR10(\n",
        "    \"datasets/cifar10\", download=True, transform=transform\n",
        ")\n",
        "# or create a dataset from a folder containing images or videos:\n",
        "# dataset = LightlyDataset(\"path/to/folder\", transform=transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model training**"
      ],
      "metadata": {
        "id": "JEkIWYlvwzC2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhvR3asIbotz",
        "outputId": "5d97831d-ac3a-4e44-cd2e-b3b35cc95136"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0jwGmFhbunG"
      },
      "outputs": [],
      "source": [
        "criterion = NegativeCosineSimilarity()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
        "\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE9oGnoebw5k",
        "outputId": "97d464d4-c54d-46f4-8b84-626ccc7eff97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training\n",
            "epoch: 00, loss: -0.49175\n",
            "epoch: 01, loss: -0.54451\n",
            "epoch: 02, loss: -0.56582\n",
            "epoch: 03, loss: -0.58042\n",
            "epoch: 04, loss: -0.58841\n",
            "epoch: 05, loss: -0.59704\n",
            "epoch: 06, loss: -0.60009\n",
            "epoch: 07, loss: -0.60295\n",
            "epoch: 08, loss: -0.60661\n",
            "epoch: 09, loss: -0.60718\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
        "    for batch in dataloader:\n",
        "        x0, x1 = batch[0]\n",
        "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
        "        update_momentum(\n",
        "            model.projection_head, model.projection_head_momentum, m=momentum_val\n",
        "        )\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        p0 = model(x0)\n",
        "        z0 = model.forward_momentum(x0)\n",
        "        p1 = model(x1)\n",
        "        z1 = model.forward_momentum(x1)\n",
        "        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion**"
      ],
      "metadata": {
        "id": "Ob-rpR55w6z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BYOL has shown impressive results in learning visual representations without labels, outperforming or matching the state-of-the-art methods on multiple benchmarks. Its effectiveness without negative pairs challenges the previously held belief that contrastive learning with negative samples was necessary for successful self-supervised learning."
      ],
      "metadata": {
        "id": "7hvIpd9Zw5Xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **References**\n",
        "\n",
        "[1] Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M. and Piot, B., 2020. **Bootstrap Your Own Latent-A New Approach to Self-Supervised Learning**. Advances in neural information processing systems, 33, pp.21271-21284.\n",
        "\n",
        "**Abstract from BYOL paper**:\n",
        "We introduce Bootstrap Your Own Latent (BYOL), a new approach to self\u0002supervised image representation learning. BYOL relies on two neural networks,\n",
        "referred to as online and target networks, that interact and learn from each other.\n",
        "From an augmented view of an image, we train the online network to predict the\n",
        "target network representation of the same image under a different augmented view.\n",
        "At the same time, we update the target network with a slow-moving average of\n",
        "the online network. While state-of-the art methods rely on negative pairs, BYOL\n",
        "achieves a new state of the art without them. BYOL reaches 74.3% top-1 classifica\u0002tion accuracy on ImageNet using a linear evaluation with a ResNet-50 architecture\n",
        "and 79.6% with a larger ResNet. We show that BYOL performs on par or better than\n",
        "the current state of the art on both transfer and semi-supervised benchmarks. Our\n",
        "implementation and pretrained models are given on GitHub.\n",
        "\n",
        "[2] **Review — BYOL: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning\n",
        "Outperforms Contrastive Learning Approaches: SimCLR, MoCo v2, CPCv2, CMC, MoCo**. https://sh-tsang.medium.com/review-byol-bootstrap-your-own-latent-a-new-approach-to-self-supervised-learning-6f770a624441\n",
        "\n",
        "[3] **BYOL —The Alternative to Contrastive Self-Supervised Learning, Paper Analysis—Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning**. https://towardsdatascience.com/byol-the-alternative-to-contrastive-self-supervised-learning-5d0a26983d7c\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oTdTN5lnw9eO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ye5Krr4y6ZXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}